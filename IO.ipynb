{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%logstop\n",
    "%logstart -rtq ~/.logs/DS_IO.py append\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expectexception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete files generated from running the notebook\n",
    "!rm -f data/my_data.txt\n",
    "!rm -f data/fail.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Exporting Data\n",
    "\n",
    "<!-- requirement: data/sample.txt -->\n",
    "<!-- requirement: data/csv_sample.txt -->\n",
    "<!-- requirement: data/bad_csv.csv -->\n",
    "\n",
    "So far we've only dealt with data that we have created within Python. Generating random data is helpful for testing out ideas, but we want to work with real data. Most often that data will be stored in a file, either locally on the computer or online. In this notebook we'll learn how to read and write data to files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python file handles (`open`)\n",
    "\n",
    "In Python we interact with files on disk using the commands `open` and `close`. We've included a file in the `data` folder called `sample.txt`. Let's open it and read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "f = open('./data/sample.txt', 'r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "print(data)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we `open` the file  and assign it to `f`, `read` the data from `f`, and then close `f`. What is `f`? It's called a **file handle**. It's an object that connects Python to the file we `open`. We `read` the data using this connection, and then once we're done with `close` the connection. It's a good habit to `close` a file handle once we're done with it, so usually we will do it automatically using Python's `with` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# f is automatically closed\n",
    "# at the end of the body of the with statement\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read individual lines of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "\n",
      "Congratulations!\n",
      "\n",
      "You've read in data from a file.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!\\n', 'Congratulations!\\n', \"You've read in data from a file.\"]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readlines())\n",
    "    print(type(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read in data from a file.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.read())\n",
    "    print(type(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data to files is very similar. The main difference is when we `open` the file, we will use the `'w'` flag instead of `'r'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'w') as f:\n",
    "    f.write('This is a new file.\\n')\n",
    "    f.write('I am practicing writing data to disk.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how often I execute the above cell, the same output gets printed. Opening the file with the `'w'` flag will overwrite the contents of the file. If we want to add to what is already in the file, we have to open the file with the `'a'` flag (`'a'` stands for _append_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n",
      "Adding a new line to the file.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'a') as f:\n",
    "    f.write('\\nAdding a new line to the file.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always need to be careful when writing to disk, because we could overwrite or alter data by accident. It is also easy to encounter errors when working with files, because we might not know ahead of time if the file we're trying to access exists, or we might mix up the `'r'`, `'w'`, and `'a'` flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-12-3a04e58b575a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;31m# (but we can open it for writing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/fail.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/fail.txt'\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# if a file doesn't exist\n",
    "# we can't open it for reading\n",
    "# (but we can open it for writing)\n",
    "\n",
    "with open('./data/fail.txt', 'r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%expect_exception IOError\n",
    "\n",
    "# we can't read a file open for writing\n",
    "\n",
    "with open('./data/fail.txt', 'w') as f:\n",
    "    f.write('Hi dumbass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-14-776a79381859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/sample.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This will fail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not writable\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# and we can't write to a file open for reading\n",
    "\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    f.write('This will fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we prevent some of these errors? How do we find out what files are on disk?\n",
    "\n",
    "## `os` module\n",
    "\n",
    "Python has a module for navigating the computer's file system called `os`. There are many useful tools in the `os` module, but there are two functions that are most useful for finding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DS_SQL.ipynb',\n",
       " 'data',\n",
       " 'miniprojects',\n",
       " 'DS_Basic_DS_Modules.ipynb',\n",
       " 'DS_IO.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'DS_Data_Munging.ipynb',\n",
       " 'DS_Classes_and_ORM.ipynb',\n",
       " '.done',\n",
       " 'DS_Intro_Statistics.ipynb',\n",
       " 'DS_Pandas.ipynb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# list the contents of the current directory\n",
    "# ('.' refers to the current directory)\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `listdir` is the simpler of the two functions we'll cover. It simply lists the contents of the directory path we specify. When we pass `'.'` as the argument, `listdir` will look in the current directory. It lists all the Jupyter notebooks we're using for the course, as well as the `data` subdirectory. We could find out what's in the `data` subdirectory by looking in `'./data'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['short_text.txt',\n",
       " 'csv_sample.txt',\n",
       " 'PEP_2016_PEPANNRES.csv',\n",
       " 'fail.txt',\n",
       " 'products.csv',\n",
       " 'orders.csv',\n",
       " 'my_data.txt',\n",
       " 'bad_csv.csv',\n",
       " 'customers.csv',\n",
       " 'short_text.txt.gz',\n",
       " 'eog_djvu_scrambled.txt.gz',\n",
       " 'eog_djvu.txt.gz',\n",
       " 'yelp.json.gz',\n",
       " 'cia_factbook.csv',\n",
       " 'pd_write.csv',\n",
       " 'library.json',\n",
       " 'eog_djvu.txt',\n",
       " 'sample.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to find all the files and subdirectories below a directory somewhere on our computer? With `listdir` we only see the files and subdirectories under the particular directory we're looking in. We cannot use `listdir` to automatically search through subdirectories. For this we need to use `walk`, which \"walks\" through all the subdirectories below our chosen directory. We won't cover `walk` in this course, but it's one of the very useful tools (along with the `os.path` sub-module) for working with files in Python, particularly if you are working with many different data files at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files\n",
    "\n",
    "One of the simplest and most common formats for saving data is as comma-separated values (CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index,name,age\n",
      "0,Dylan,28\n",
      "1,Terrence,54\n",
      "2,Mya,31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    csv = f.read()\n",
    "\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  age\n",
      "index               \n",
      "0         Dylan   28\n",
      "1      Terrence   54\n",
      "2           Mya   31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_ = pd.read_csv('./data/csv_sample.txt', index_col=0)\n",
    "print(csv_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is often used to represent tables of data. Usually a CSV will have rows (separated by newline characters, `'\\n'`) and columns (separated by commas). Otherwise they are no different from any other text file. We can use the special formatting of a CSV to create a list of lists representing the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " ['0', 'Dylan', '28'],\n",
       " ['1', 'Terrence', '54'],\n",
       " ['2', 'Mya', '31']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        list_table.append(line.strip().split(','))\n",
    "\n",
    "list_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " row(index=0, name='Dylan', age=28),\n",
       " row(index=1, name='Terrence', age=54),\n",
       " row(index=2, name='Mya', age=31)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Row = namedtuple('row', ['index', 'name', 'age'])\n",
    "\n",
    "def parse_line(line):\n",
    "    row = line.strip().split(',')\n",
    "    if row[0] == 'index':\n",
    "        return row\n",
    "    return Row(int(row[0]), row[1], int(row[2]))\n",
    "\n",
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        list_table.append(parse_line(line))\n",
    "\n",
    "list_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can work with tabular data much more easily in a Pandas DataFrame. Pandas provides a `read_csv` method to read the data directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dylan</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrence</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mya</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age\n",
       "index               \n",
       "0         Dylan   28\n",
       "1      Terrence   54\n",
       "2           Mya   31"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/csv_sample.txt', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` method is very flexible to deal with the formatting of different data sets. Some data sets will include column headers while others may not. Some data sets will include an index while others may not. Some data sets may have values separated by tabs, semicolons, or other characters instead of commas. There are options in the `read_csv` method for dealing with all of these. You can read about them in the [Pandas documentation on `read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). We'll also discuss it further in the [Pandas notebook](DS_Pandas.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-29 00:56:36--  https://www.openintro.org/data/csv/cia_factbook.csv\n",
      "Resolving www.openintro.org (www.openintro.org)... 192.185.65.127\n",
      "Connecting to www.openintro.org (www.openintro.org)|192.185.65.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16939 (17K) [text/csv]\n",
      "Saving to: ‘./data/cia_factbook.csv.1’\n",
      "\n",
      "cia_factbook.csv.1  100%[===================>]  16.54K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2021-07-29 00:56:36 (402 KB/s) - ‘./data/cia_factbook.csv.1’ saved [16939/16939]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>area</th>\n",
       "      <th>birth_rate</th>\n",
       "      <th>death_rate</th>\n",
       "      <th>infant_mortality_rate</th>\n",
       "      <th>internet_users</th>\n",
       "      <th>life_exp_at_birth</th>\n",
       "      <th>maternal_mortality_rate</th>\n",
       "      <th>net_migration_rate</th>\n",
       "      <th>population</th>\n",
       "      <th>population_growth_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia</td>\n",
       "      <td>17098242.0</td>\n",
       "      <td>11.87</td>\n",
       "      <td>13.83</td>\n",
       "      <td>7.08</td>\n",
       "      <td>40853000.0</td>\n",
       "      <td>70.16</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.424703e+08</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9984670.0</td>\n",
       "      <td>10.29</td>\n",
       "      <td>8.31</td>\n",
       "      <td>4.71</td>\n",
       "      <td>26960000.0</td>\n",
       "      <td>81.67</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.483484e+07</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>9826675.0</td>\n",
       "      <td>13.42</td>\n",
       "      <td>8.15</td>\n",
       "      <td>6.17</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>79.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.188921e+08</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>9596960.0</td>\n",
       "      <td>12.17</td>\n",
       "      <td>7.44</td>\n",
       "      <td>14.79</td>\n",
       "      <td>389000000.0</td>\n",
       "      <td>75.15</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.355693e+09</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>8514877.0</td>\n",
       "      <td>14.72</td>\n",
       "      <td>6.54</td>\n",
       "      <td>19.21</td>\n",
       "      <td>75982000.0</td>\n",
       "      <td>73.28</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2.026568e+08</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country        area  birth_rate  death_rate  infant_mortality_rate  \\\n",
       "0         Russia  17098242.0       11.87       13.83                   7.08   \n",
       "1         Canada   9984670.0       10.29        8.31                   4.71   \n",
       "2  United States   9826675.0       13.42        8.15                   6.17   \n",
       "3          China   9596960.0       12.17        7.44                  14.79   \n",
       "4         Brazil   8514877.0       14.72        6.54                  19.21   \n",
       "\n",
       "   internet_users  life_exp_at_birth  maternal_mortality_rate  \\\n",
       "0      40853000.0              70.16                     34.0   \n",
       "1      26960000.0              81.67                     12.0   \n",
       "2     245000000.0              79.56                     21.0   \n",
       "3     389000000.0              75.15                     37.0   \n",
       "4      75982000.0              73.28                     56.0   \n",
       "\n",
       "   net_migration_rate    population  population_growth_rate  \n",
       "0                1.69  1.424703e+08                   -0.03  \n",
       "1                5.66  3.483484e+07                    0.76  \n",
       "2                2.45  3.188921e+08                    0.77  \n",
       "3               -0.32  1.355693e+09                    0.44  \n",
       "4               -0.15  2.026568e+08                    0.80  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of downloading\n",
    "# and importing real data using `read_csv`\n",
    "\n",
    "if 'factbook.csv' not in os.listdir('./data/'):\n",
    "    !wget -P ./data/ https://www.openintro.org/data/csv/cia_factbook.csv\n",
    "\n",
    "countries = pd.read_csv('./data/cia_factbook.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a      b\n",
       "0   0   True\n",
       "1   3   True\n",
       "2  10  False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use pandas to write CSV\n",
    "# using the DataFrame's to_csv method\n",
    "\n",
    "pd.DataFrame({'a': [0, 3, 10], 'b': [True, True, False]}).to_csv('./data/pd_write.csv')\n",
    "\n",
    "pd.read_csv('./data/pd_write.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a CSV won't be perfect. For example, maybe different rows have different numbers of commas. This makes it difficult to interpret the contents of the file as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index,name,age\r\n",
      "0,Dylan,27\r\n",
      "1,54\r\n",
      "2,Mya,31"
     ]
    }
   ],
   "source": [
    "# the 3rd line only has 2 \"columns\"\n",
    "\n",
    "!cat ./data/bad_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dylan</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mya</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   age\n",
       "index             \n",
       "0      Dylan  27.0\n",
       "1         54   NaN\n",
       "2        Mya  31.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what happens if we try to read this\n",
    "# into a DataFrame using read_csv?\n",
    "\n",
    "pd.read_csv('./data/bad_csv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' `read_csv` method will do its best to construct a table out of a poorly formatted CSV, but it may make mistakes. For example, 54 was interpreted as a name instead of as an age, because there were only 2 columns in that line of the file. Data sets will often contain mistakes like bad formatting, missing data, or typos.\n",
    "\n",
    "**Question:** How could we fix the badly formatted CSV so it would work with `read_csv`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "JSON stands for JavaScript Object Notation. JavaScript is a common language for creating web applications, and JSON files are used to collect and transmit information between JavaScript applications. As a result, a lot of data on the internet exists in the JSON file format. For example, Twitter and Google Maps use JSON.\n",
    "\n",
    "A JSON file is essentially a data structure built out of nested dictionaries and lists. Let's make our own example and then we'll examine an example downloaded from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1 = {'title': 'The Prophet',\n",
    "         'author': 'Khalil Gibran',\n",
    "         'genre': 'poetry',\n",
    "         'tags': ['religion', 'spirituality', 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
    "         'book_id': '811.19',\n",
    "         'copies': [{'edition_year': 1996,\n",
    "                     'checkouts': 486,\n",
    "                     'borrowed': False},\n",
    "                    {'edition_year': 1996,\n",
    "                     'checkouts': 443,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "         \n",
    "book2 = {'title': 'The Little Prince',\n",
    "         'author': 'Antoine de Saint-Exupery',\n",
    "         'genre': 'children',\n",
    "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
    "         'id': '843.912',\n",
    "         'copies': [{'edition_year': 1983,\n",
    "                     'checkouts': 634,\n",
    "                     'borrowed': True,\n",
    "                     'due_date': '2017/02/02'},\n",
    "                    {'edition_year': 2015,\n",
    "                     'checkouts': 41,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "\n",
    "library = [book1, book2]\n",
    "library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two books in our `library`. Both books have some common properties: a title, an author, an id, and tags. Each book can have several tags, so we store that data as a list. Additionally, there can be multiple copies of each book, and each copy also has some unique information like the year it was printed and how many times it's been checked out. Notice that if a book is checked out, it also has a due date. It's convenient to store the information about the multiple copies as a list of dictionaries within the dictionary about the book, because every copy shares the same title, author, etc.\n",
    "\n",
    "This structure is typical of JSON files. It has the advantage of reducing redundancy of data. We only store the author and title once, even though there are multiple copies of the book. Also, we don't store a due date for copies that aren't checked out.\n",
    "\n",
    "If we were to put this data in a table, we would have to duplicate a lot of information. Also, since only one copy in our library is checked out, we also have a column with a lot of missing data.\n",
    "\n",
    "|index|title|author|id|genre|tags|edition_year|checkouts|borrowed|due_date|\n",
    "|:---:|:---:|:----:|::|:---:|:--:|:----------:|:-------:|:------:|:------:|\n",
    "|0|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|486|False|Null|\n",
    "|1|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|443|False|Null|\n",
    "|2|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|1983|634|True|2017/02/02|\n",
    "|3|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|2015|41|False|Null|\n",
    "\n",
    "This is very wasteful. Since JSON files are meant to be shared quickly over the internet, it is important that they are small to reduce the amount of resources needed to store and transmit them.\n",
    "\n",
    "We can write our `library` to disk using the `json` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/library.json', 'w') as f:\n",
    "    json.dump(library, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"title\": \"The Prophet\",\r\n",
      "    \"author\": \"Khalil Gibran\",\r\n",
      "    \"genre\": \"poetry\",\r\n",
      "    \"tags\": [\r\n",
      "      \"religion\",\r\n",
      "      \"spirituality\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"Lebanon\",\r\n",
      "      \"Arabic\",\r\n",
      "      \"Middle East\"\r\n",
      "    ],\r\n",
      "    \"book_id\": \"811.19\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 486,\r\n",
      "        \"borrowed\": false\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 443,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"title\": \"The Little Prince\",\r\n",
      "    \"author\": \"Antoine de Saint-Exupery\",\r\n",
      "    \"genre\": \"children\",\r\n",
      "    \"tags\": [\r\n",
      "      \"fantasy\",\r\n",
      "      \"France\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"illustrated\",\r\n",
      "      \"fable\"\r\n",
      "    ],\r\n",
      "    \"id\": \"843.912\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1983,\r\n",
      "        \"checkouts\": 634,\r\n",
      "        \"borrowed\": true,\r\n",
      "        \"due_date\": \"2017/02/02\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 2015,\r\n",
      "        \"checkouts\": 41,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat ./data/library.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/library.json', 'r') as f:\n",
    "    reloaded_library = json.load(f)\n",
    "\n",
    "reloaded_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_library == library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"title\": \"The Prophet\",\\n    \"author\": \"Khalil Gibran\",\\n    \"genre\": \"poetry\",\\n    \"tags\": [\\n      \"religion\",\\n      \"spirituality\",\\n      \"philosophy\",\\n      \"Lebanon\",\\n      \"Arabic\",\\n      \"Middle East\"\\n    ],\\n    \"book_id\": \"811.19\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 486,\\n        \"borrowed\": false\\n      },\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 443,\\n        \"borrowed\": false\\n      }\\n    ]\\n  },\\n  {\\n    \"title\": \"The Little Prince\",\\n    \"author\": \"Antoine de Saint-Exupery\",\\n    \"genre\": \"children\",\\n    \"tags\": [\\n      \"fantasy\",\\n      \"France\",\\n      \"philosophy\",\\n      \"illustrated\",\\n      \"fable\"\\n    ],\\n    \"id\": \"843.912\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1983,\\n        \"checkouts\": 634,\\n        \"borrowed\": true,\\n        \"due_date\": \"2017/02/02\"\\n      },\\n      {\\n        \"edition_year\": 2015,\\n        \"checkouts\": 41,\\n        \"borrowed\": false\\n      }\\n    ]\\n  }\\n]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that if we loaded it in without JSON\n",
    "# the file would be interpreted as plain text\n",
    "\n",
    "with open('./data/library.json', 'r') as f:\n",
    "    library_string = f.read()\n",
    "\n",
    "# this isn't what we want\n",
    "library_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(library_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>tags</th>\n",
       "      <th>book_id</th>\n",
       "      <th>copies</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prophet</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>poetry</td>\n",
       "      <td>[religion, spirituality, philosophy, Lebanon, ...</td>\n",
       "      <td>811.19</td>\n",
       "      <td>[{'edition_year': 1996, 'checkouts': 486, 'bor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Little Prince</td>\n",
       "      <td>Antoine de Saint-Exupery</td>\n",
       "      <td>children</td>\n",
       "      <td>[fantasy, France, philosophy, illustrated, fable]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'edition_year': 1983, 'checkouts': 634, 'bor...</td>\n",
       "      <td>843.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                    author     genre  \\\n",
       "0        The Prophet             Khalil Gibran    poetry   \n",
       "1  The Little Prince  Antoine de Saint-Exupery  children   \n",
       "\n",
       "                                                tags  book_id  \\\n",
       "0  [religion, spirituality, philosophy, Lebanon, ...   811.19   \n",
       "1  [fantasy, France, philosophy, illustrated, fable]      NaN   \n",
       "\n",
       "                                              copies       id  \n",
       "0  [{'edition_year': 1996, 'checkouts': 486, 'bor...      NaN  \n",
       "1  [{'edition_year': 1983, 'checkouts': 634, 'bor...  843.912  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas can also read_json\n",
    "# notice how it constructs the table\n",
    "# does it represent the data well?\n",
    "import pandas as pd\n",
    "pd.read_json('./data/library.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":{\"0\":\"Dylan\",\"1\":\"Terrence\",\"2\":\"Mya\"},\"age\":{\"0\":28,\"1\":54,\"2\":31}}"
     ]
    }
   ],
   "source": [
    "# and to_json\n",
    "df.to_json('./data/example_df.json')\n",
    "\n",
    "!head ./data/example_df.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download JSON files many ways. Sometimes we will download it manually, but we can also use `wget` like we did for the CSV example. Often we'll connect to a website's API which will respond using JSON.\n",
    "\n",
    "Panda's `read_json` method is capable of connecting directly to a URL (whether it's the address of a JSON file or an API connection) and reading the JSON without saving the file to our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>milestone</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>body</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/42787</td>\n",
       "      <td>955297453</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0Njk5MDY4OTA5</td>\n",
       "      <td>42787</td>\n",
       "      <td>BUG: 1D slices over extension types turn into ...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-28 23:05:15+00:00</td>\n",
       "      <td>2021-07-28 23:05:43+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>- [X] closes #42430\\r\\n- [X] tests added / pas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/42786</td>\n",
       "      <td>955290695</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0Njk5MDYzMDY4</td>\n",
       "      <td>42786</td>\n",
       "      <td>Backport PR #42762 on branch 1.3.x (REG: DataF...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-28 22:50:10+00:00</td>\n",
       "      <td>2021-07-28 22:50:11+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>Backport PR #42762: REG: DataFrame.agg where f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/42785</td>\n",
       "      <td>955210497</td>\n",
       "      <td>MDU6SXNzdWU5NTUyMTA0OTc=</td>\n",
       "      <td>42785</td>\n",
       "      <td>BUG: Multiindex Categorical type lost after di...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-28 20:29:52+00:00</td>\n",
       "      <td>2021-07-28 20:58:58+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- [X] I have checked that this issue has not a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/42784</td>\n",
       "      <td>955189452</td>\n",
       "      <td>MDU6SXNzdWU5NTUxODk0NTI=</td>\n",
       "      <td>42784</td>\n",
       "      <td>ENH: Support Left Semi Joins</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-28 19:59:06+00:00</td>\n",
       "      <td>2021-07-28 20:02:08+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#### Is your feature request related to a prob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/42783</td>\n",
       "      <td>955170551</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0Njk4OTU5NzE5</td>\n",
       "      <td>42783</td>\n",
       "      <td>TST: Fix doctests in style.py</td>\n",
       "      <td>...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-28 19:29:59+00:00</td>\n",
       "      <td>2021-07-28 22:51:39+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>The following commits fix the doctests of the ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                   repository_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                            html_url         id  \\\n",
       "0    https://github.com/pandas-dev/pandas/pull/42787  955297453   \n",
       "1    https://github.com/pandas-dev/pandas/pull/42786  955290695   \n",
       "2  https://github.com/pandas-dev/pandas/issues/42785  955210497   \n",
       "3  https://github.com/pandas-dev/pandas/issues/42784  955189452   \n",
       "4    https://github.com/pandas-dev/pandas/pull/42783  955170551   \n",
       "\n",
       "                            node_id  number  \\\n",
       "0  MDExOlB1bGxSZXF1ZXN0Njk5MDY4OTA5   42787   \n",
       "1  MDExOlB1bGxSZXF1ZXN0Njk5MDYzMDY4   42786   \n",
       "2          MDU6SXNzdWU5NTUyMTA0OTc=   42785   \n",
       "3          MDU6SXNzdWU5NTUxODk0NTI=   42784   \n",
       "4  MDExOlB1bGxSZXF1ZXN0Njk4OTU5NzE5   42783   \n",
       "\n",
       "                                               title  ...  \\\n",
       "0  BUG: 1D slices over extension types turn into ...  ...   \n",
       "1  Backport PR #42762 on branch 1.3.x (REG: DataF...  ...   \n",
       "2  BUG: Multiindex Categorical type lost after di...  ...   \n",
       "3                       ENH: Support Left Semi Joins  ...   \n",
       "4                      TST: Fix doctests in style.py  ...   \n",
       "\n",
       "                                           milestone comments  \\\n",
       "0                                               None        0   \n",
       "1  {'url': 'https://api.github.com/repos/pandas-d...        0   \n",
       "2                                               None        0   \n",
       "3                                               None        1   \n",
       "4  {'url': 'https://api.github.com/repos/pandas-d...        1   \n",
       "\n",
       "                 created_at                updated_at  closed_at  \\\n",
       "0 2021-07-28 23:05:15+00:00 2021-07-28 23:05:43+00:00        NaT   \n",
       "1 2021-07-28 22:50:10+00:00 2021-07-28 22:50:11+00:00        NaT   \n",
       "2 2021-07-28 20:29:52+00:00 2021-07-28 20:58:58+00:00        NaT   \n",
       "3 2021-07-28 19:59:06+00:00 2021-07-28 20:02:08+00:00        NaT   \n",
       "4 2021-07-28 19:29:59+00:00 2021-07-28 22:51:39+00:00        NaT   \n",
       "\n",
       "  author_association active_lock_reason  \\\n",
       "0        CONTRIBUTOR                NaN   \n",
       "1               NONE                NaN   \n",
       "2               NONE                NaN   \n",
       "3               NONE                NaN   \n",
       "4               NONE                NaN   \n",
       "\n",
       "                                        pull_request  \\\n",
       "0  {'url': 'https://api.github.com/repos/pandas-d...   \n",
       "1  {'url': 'https://api.github.com/repos/pandas-d...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'url': 'https://api.github.com/repos/pandas-d...   \n",
       "\n",
       "                                                body performed_via_github_app  \n",
       "0  - [X] closes #42430\\r\\n- [X] tests added / pas...                      NaN  \n",
       "1  Backport PR #42762: REG: DataFrame.agg where f...                      NaN  \n",
       "2  - [X] I have checked that this issue has not a...                      NaN  \n",
       "3  #### Is your feature request related to a prob...                      NaN  \n",
       "4  The following commits fix the doctests of the ...                      NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('https://api.github.com/repos/pydata/pandas/issues?per_page=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed files (Gzip)\n",
    "\n",
    "Another way we save storage and network resources is by using **compression**. Many times data sets will contain patterns that can be used to reduce the amount of space needed to store the information.\n",
    "\n",
    "A simple example is the following list of numbers: 10, 10, 10, 2, 3, 3, 3, 3, 3, 50, 50, 1, 1, 50, 10, 10, 10, 10\n",
    "\n",
    "Rather than writing out the full list of numbers (18 integers), we can represent the same information with only 14 numbers: (3, 10), (1, 2), (5, 3), (2, 50), (2, 1), (1, 50), (4, 10)\n",
    "\n",
    "Here the first number in each pair is the number of repetitions, and the second number in the pair is the actual value. We've successfully reduced the amount of numbers we need to represent the same data. Most forms of compression use a similar idea, although actual implementations are usually more complex.\n",
    "\n",
    "In the world of data science, the most common compression is Gzip (which uses the [deflate algorithm](http://www.infinitepartitions.com/art001.html)). Gzip files end with the extension `.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-29 00:56:40--  https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘./data/eog_djvu.txt.1’\n",
      "\n",
      "eog_djvu.txt.1          [ <=>                ] 203.17K  1.15MB/s    in 0.2s    \n",
      "\n",
      "2021-07-29 00:56:40 (1.15 MB/s) - ‘./data/eog_djvu.txt.1’ saved [208050]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./data/ https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 jovyan users 193K Jul 28 01:15 ./data/eog_djvu_scrambled.txt.gz\r\n",
      "-rw-rw-r-- 1 jovyan users 204K Jul 28 01:08 ./data/eog_djvu.txt\r\n",
      "-rw-r--r-- 1 jovyan users 204K Jul 29 00:56 ./data/eog_djvu.txt.1\r\n",
      "-rw-rw-r-- 1 jovyan users  60K Jul 29 00:56 ./data/eog_djvu.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "with open('./data/eog_djvu.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with gzip.open('./data/eog_djvu.txt.gz', 'wb') as f:\n",
    "    f.write(text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to compress the text of The Epic of Gilgamesh to a third of its original size! Remember that compression depends on patterns in the data. Language has a lot of patterns, but what would happen if we scrambled all the letters in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 jovyan users 192K Jul 29 00:56 ./data/eog_djvu_scrambled.txt.gz\r\n",
      "-rw-rw-r-- 1 jovyan users 204K Jul 28 01:08 ./data/eog_djvu.txt\r\n",
      "-rw-r--r-- 1 jovyan users 204K Jul 29 00:56 ./data/eog_djvu.txt.1\r\n",
      "-rw-rw-r-- 1 jovyan users  60K Jul 29 00:56 ./data/eog_djvu.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with gzip.open('./data/eog_djvu_scrambled.txt.gz', 'wb') as f:\n",
    "    f.write(np.random.permutation(list(text)))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrambled version only compressed to two-thirds the size of the original. Compression won't perform very well on random data. Compression also doesn't work very well on data that is already small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 jovyan users  5 Jul 29 00:56 ./data/short_text.txt\r\n",
      "-rw-rw-r-- 1 jovyan users 40 Jul 29 00:56 ./data/short_text.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "short_text = 'Hello'\n",
    "\n",
    "with open('./data/short_text.txt', 'w') as f:\n",
    "    f.write(short_text)\n",
    "\n",
    "with gzip.open('./data/short_text.txt.gz', 'wb') as f:\n",
    "    f.write(short_text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/short_text*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed file is bigger than the plain text! That's because the compressed file includes a header, which takes up a small amount of extra space. Also, since the text is so short, it's not possible to use patterns to represent the text more efficiently. Therefore we usually save compression for large files.\n",
    "\n",
    "You may have noticed that when we write Gzip files, we have been using a `'wb'` flag instead of a plain `'w'` flag. This is because Gzip is not plain text. When compressing the file we write _binary_ files. The files are not readable as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b��\u0001a\u0002�short_text.txt\u0000�H���\u0007\u0000����\u0005\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "# we have to uncompress the file\n",
    "# before we can read it\n",
    "\n",
    "!cat ./data/short_text.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should only use `'w'` for plain text files (which includes CSV and JSON). Using `'w'` instead of `'wb'` for Gzip files, or other files which are not plain text (e.g. images), could damage the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization (`pickle`)\n",
    "\n",
    "Often we will want to save our work in Python and come back to it later. However, that work might be a machine learning model or some other complex object in Python. How do we save complex Python objects? Python has a module for this purpose called `pickle`. We can use `pickle` to write a binary file that contains all the information about a Python object. Later we can load that pickle file and reconstruct the object in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_example = ['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-42-a9c72e388869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m# we can't save this as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/pickle_example.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception TypeError\n",
    "\n",
    "# we can't save this as text\n",
    "with open('./data/pickle_example.txt', 'w') as f:\n",
    "    f.write(pickle_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_example.json', 'w') as f:\n",
    "    json.dump(pickle_example, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, [1, 2, 3], [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/pickle_example.json', 'r') as f:\n",
    "    pickle_json = json.load(f)\n",
    "\n",
    "pickle_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/pickle_example.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_example, f)\n",
    "with open('./data/pickle_example.pkl', 'rb') as f:\n",
    "    reloaded_pickle = pickle.load(f)\n",
    "\n",
    "reloaded_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the reloaded example is the same as the original\n",
    "\n",
    "reloaded_example == pickle_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is an important tool for data scientists. Data processing and training machine learning models can take a long time, and it is useful to save checkpoints.\n",
    "\n",
    "Pandas also has `to_pickle` and `read_pickle` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy file formats\n",
    "\n",
    "NumPy also has methods for saving and loading data. They are straightforward to use. You may encounter these when working with certain machine learning libraries that require data be stored in NumPy arrays. NumPy arrays are also often used when working with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23295745 0.60009061 0.03963324 0.59982804]\n",
      " [0.01143172 0.76065107 0.73689047 0.80328372]\n",
      " [0.97495103 0.92592755 0.71370862 0.23445034]\n",
      " [0.93248108 0.96763913 0.04027293 0.66634547]]\n"
     ]
    }
   ],
   "source": [
    "sample_array = np.random.random((4, 4))\n",
    "print(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as plain text\n",
    "np.savetxt('./data/sample_array.txt', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.329574470831695665e-01 6.000906124068353664e-01 3.963324484876951104e-02 5.998280407619300814e-01\r\n",
      "1.143171578508073161e-02 7.606510748245880471e-01 7.368904715970719943e-01 8.032837207925469514e-01\r\n",
      "9.749510292722854965e-01 9.259275480629530763e-01 7.137086243708963273e-01 2.344503350402145081e-01\r\n",
      "9.324810765667151946e-01 9.676391299312721017e-01 4.027292768008683410e-02 6.663454673913564719e-01\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23295745 0.60009061 0.03963324 0.59982804]\n",
      " [0.01143172 0.76065107 0.73689047 0.80328372]\n",
      " [0.97495103 0.92592755 0.71370862 0.23445034]\n",
      " [0.93248108 0.96763913 0.04027293 0.66634547]]\n"
     ]
    }
   ],
   "source": [
    "print(np.loadtxt('./data/sample_array.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as compressed binary\n",
    "np.save('./data/sample_array.npy', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�NUMPY\u0001\u0000v\u0000{'descr': '<f8', 'fortran_order': False, 'shape': (4, 4), }                                                          \r\n",
      "�zJ����?)�]:�3�?@n�\u0004�J�?�zI��1�?�\u0003y�i�?L>A�@W�?EʇS���?h��\u000f���?ա=��2�?Ѫ,�2��?\f",
      "z\u0011x���?�X��w\u0002�?�������?�O,V���?���6���?(\u0014ɺ�R�?"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23295745 0.60009061 0.03963324 0.59982804]\n",
      " [0.01143172 0.76065107 0.73689047 0.80328372]\n",
      " [0.97495103 0.92592755 0.71370862 0.23445034]\n",
      " [0.93248108 0.96763913 0.04027293 0.66634547]]\n"
     ]
    }
   ],
   "source": [
    "print(np.load('./data/sample_array.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 256 Jul 29 00:56 ./data/sample_array.npy\r\n",
      "-rw-r--r-- 1 jovyan users 400 Jul 29 00:56 ./data/sample_array.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./data/sample_array.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics used by not discussed:\n",
    "- BASH commands (!)\n",
    "- `wget`\n",
    "- `str.split()`\n",
    "- APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2021 WorldQuant University. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
